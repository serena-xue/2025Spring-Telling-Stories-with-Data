{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T03:56:24.741152Z",
     "start_time": "2025-02-05T03:56:24.357646Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_path = './data'\n",
    "\n",
    "df_menu = pd.read_csv(os.path.join(data_path, 'Menu.csv'))"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:31:26.432808Z",
     "start_time": "2025-02-05T04:31:26.428736Z"
    }
   },
   "cell_type": "code",
   "source": "len(df_menu)",
   "id": "50c98fd78c37faf1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17545"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T03:50:42.853746Z",
     "start_time": "2025-02-05T03:50:42.847835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "locations = df_menu.location.unique()\n",
    "pd.DataFrame(locations)"
   ],
   "id": "28195b3ebe2105dd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                      0\n",
       "0                                         Hotel Eastman\n",
       "1                                      Republican House\n",
       "2                            Norddeutscher Lloyd Bremen\n",
       "3                      Canadian Pacific Railway Company\n",
       "4                                      Hotel Netherland\n",
       "...                                                 ...\n",
       "6278                                       The Richmond\n",
       "6279                                  Pabst 14th Street\n",
       "6280                                     Woolpack Hotel\n",
       "6281           Hotel Schynige Platte und Hotel Bellevue\n",
       "6282  Christmas Dinner, Troop F 19: Fort Huachuca, A...\n",
       "\n",
       "[6283 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hotel Eastman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Republican House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norddeutscher Lloyd Bremen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canadian Pacific Railway Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hotel Netherland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>The Richmond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>Pabst 14th Street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280</th>\n",
       "      <td>Woolpack Hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6281</th>\n",
       "      <td>Hotel Schynige Platte und Hotel Bellevue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6282</th>\n",
       "      <td>Christmas Dinner, Troop F 19: Fort Huachuca, A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6283 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T03:57:43.931643Z",
     "start_time": "2025-02-05T03:57:43.920123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "aa = df_menu[['sponsor', 'location']]\n",
    "# find not same pairs, case not sensitive\n",
    "aa[~aa.sponsor.str.lower().eq(aa.location.str.lower())]"
   ],
   "id": "4ba7cf829a19845a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           sponsor  \\\n",
       "15                                             NaN   \n",
       "33                                     CUNARD LINE   \n",
       "45                   RED STAR LINE - S.S.SOUTHWARK   \n",
       "49                                    REVERE HOUSE   \n",
       "57                           HAMBURG-AMERIKA LINIE   \n",
       "...                                            ...   \n",
       "14036  [Restaurant Name And/Or Location Not Given]   \n",
       "14037  [Restaurant Name And/Or Location Not Given]   \n",
       "14120  [Restaurant Name And/Or Location Not Given]   \n",
       "14248                                  The Berkley   \n",
       "14250                                  The Berkley   \n",
       "\n",
       "                               location  \n",
       "15                Occidental & Oriental  \n",
       "33     Canadian Pacific Railway Company  \n",
       "45        Red Star Line   S.S.Southwark  \n",
       "49                         Parker House  \n",
       "57                Hamburg Amerika Linie  \n",
       "...                                 ...  \n",
       "14036      Advertising Club of New York  \n",
       "14037                    John Wanamaker  \n",
       "14120             Old Colony Club, Inc.  \n",
       "14248                      The Berkeley  \n",
       "14250                      The Berkeley  \n",
       "\n",
       "[2841 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sponsor</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Occidental &amp; Oriental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>CUNARD LINE</td>\n",
       "      <td>Canadian Pacific Railway Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RED STAR LINE - S.S.SOUTHWARK</td>\n",
       "      <td>Red Star Line   S.S.Southwark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>REVERE HOUSE</td>\n",
       "      <td>Parker House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>HAMBURG-AMERIKA LINIE</td>\n",
       "      <td>Hamburg Amerika Linie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14036</th>\n",
       "      <td>[Restaurant Name And/Or Location Not Given]</td>\n",
       "      <td>Advertising Club of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14037</th>\n",
       "      <td>[Restaurant Name And/Or Location Not Given]</td>\n",
       "      <td>John Wanamaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14120</th>\n",
       "      <td>[Restaurant Name And/Or Location Not Given]</td>\n",
       "      <td>Old Colony Club, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14248</th>\n",
       "      <td>The Berkley</td>\n",
       "      <td>The Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14250</th>\n",
       "      <td>The Berkley</td>\n",
       "      <td>The Berkeley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2841 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:26:30.134299Z",
     "start_time": "2025-02-05T04:26:30.128787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "currencys = df_menu.currency.unique()\n",
    "pd.DataFrame(currencys)"
   ],
   "id": "d96ee1f3f9f82918",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             0\n",
       "0                          NaN\n",
       "1                      Dollars\n",
       "2                        Cents\n",
       "3                       Francs\n",
       "4               Belgian Francs\n",
       "5                    Shillings\n",
       "6               Deutsche Marks\n",
       "7                    UK Pounds\n",
       "8                        Pence\n",
       "9             Canadian Dollars\n",
       "10     Austro-Hungarian Kronen\n",
       "11                Swiss Francs\n",
       "12                     Pesetas\n",
       "13               Danish kroner\n",
       "14     Swedish kronor (SEK/kr)\n",
       "15                     Escudos\n",
       "16                         Yen\n",
       "17                Italian Lire\n",
       "18               Mexican pesos\n",
       "19                   Quetzales\n",
       "20   Israeli lirot (1948-1980)\n",
       "21           Monégasque francs\n",
       "22                Qatari riyal\n",
       "23              Dutch Guilders\n",
       "24         Austrian Schillings\n",
       "25                       Euros\n",
       "26            Norwegian kroner\n",
       "27             Moroccan Dirham\n",
       "28           Bermudian dollars\n",
       "29            Hungarian forint\n",
       "30                    Drachmas\n",
       "31           New Taiwan Dollar\n",
       "32            Icelandic Krónur\n",
       "33          Australian Dollars\n",
       "34              Argentine peso\n",
       "35                         Sol\n",
       "36             Uruguayan pesos\n",
       "37         Brazilian Cruzeiros\n",
       "38                       Złoty\n",
       "39                 Cuban pesos\n",
       "40              Finnish markka\n",
       "41                        Lats\n",
       "42  Straits dollar (1904-1939)"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Francs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belgian Francs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shillings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deutsche Marks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UK Pounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canadian Dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austro-Hungarian Kronen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Swiss Francs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pesetas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Danish kroner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Swedish kronor (SEK/kr)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Escudos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Italian Lire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mexican pesos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Quetzales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Israeli lirot (1948-1980)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Monégasque francs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Qatari riyal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dutch Guilders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Austrian Schillings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Euros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Norwegian kroner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Moroccan Dirham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bermudian dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hungarian forint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Drachmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>New Taiwan Dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Icelandic Krónur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Australian Dollars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Argentine peso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Uruguayan pesos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brazilian Cruzeiros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Złoty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Cuban pesos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Finnish markka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Straits dollar (1904-1939)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:26:54.949997Z",
     "start_time": "2025-02-05T04:26:54.944534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Frequency of currency\n",
    "df_menu.currency.value_counts()"
   ],
   "id": "726a281486c00639",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "currency\n",
       "Dollars                       5549\n",
       "Deutsche Marks                 293\n",
       "Francs                         162\n",
       "Canadian Dollars                98\n",
       "Swiss Francs                    47\n",
       "Shillings                       40\n",
       "Swedish kronor (SEK/kr)         39\n",
       "Italian Lire                    28\n",
       "Cents                           24\n",
       "UK Pounds                       22\n",
       "Belgian Francs                  20\n",
       "Mexican pesos                   19\n",
       "Dutch Guilders                  17\n",
       "Austrian Schillings             15\n",
       "Danish kroner                   14\n",
       "Yen                              9\n",
       "Euros                            7\n",
       "Pesetas                          7\n",
       "Escudos                          5\n",
       "Austro-Hungarian Kronen          5\n",
       "Hungarian forint                 4\n",
       "Drachmas                         4\n",
       "Norwegian kroner                 3\n",
       "Icelandic Krónur                 3\n",
       "Israeli lirot (1948-1980)        3\n",
       "Quetzales                        2\n",
       "Argentine peso                   2\n",
       "Pence                            1\n",
       "Monégasque francs                1\n",
       "Qatari riyal                     1\n",
       "Moroccan Dirham                  1\n",
       "Bermudian dollars                1\n",
       "New Taiwan Dollar                1\n",
       "Australian Dollars               1\n",
       "Sol                              1\n",
       "Uruguayan pesos                  1\n",
       "Brazilian Cruzeiros              1\n",
       "Złoty                            1\n",
       "Cuban pesos                      1\n",
       "Finnish markka                   1\n",
       "Lats                             1\n",
       "Straits dollar (1904-1939)       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:30:07.176262Z",
     "start_time": "2025-02-05T04:30:07.171502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "physical_descriptions = df_menu.physical_description.unique()\n",
    "pd.DataFrame(physical_descriptions)"
   ],
   "id": "71912f4386814019",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     0\n",
       "0                      CARD; 4.75X7.5;\n",
       "1           CARD; ILLUS; COL; 7.0X9.0;\n",
       "2            CARD; ILLU; COL; 5.5X8.0;\n",
       "3          FOLDER; ILLU; COL; 5.5X7.5;\n",
       "4         CARD; ILLUS; COL; 4.75X7.25;\n",
       "...                                ...\n",
       "6264  15.5x13cm folded; 15.5x26cm open\n",
       "6265  19.5x14cm folded; 19.5x42cm open\n",
       "6266                      19.5x11.5cm \n",
       "6267                        12.5x7.5cm\n",
       "6268  23x16.5cm folded; 23x33cm open  \n",
       "\n",
       "[6269 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARD; 4.75X7.5;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARD; ILLUS; COL; 7.0X9.0;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CARD; ILLU; COL; 5.5X8.0;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOLDER; ILLU; COL; 5.5X7.5;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CARD; ILLUS; COL; 4.75X7.25;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>15.5x13cm folded; 15.5x26cm open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>19.5x14cm folded; 19.5x42cm open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6266</th>\n",
       "      <td>19.5x11.5cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6267</th>\n",
       "      <td>12.5x7.5cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6268</th>\n",
       "      <td>23x16.5cm folded; 23x33cm open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6269 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:31:06.816691Z",
     "start_time": "2025-02-05T04:31:06.804987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 筛选出 physical_descriptions 中包含数字的行\n",
    "df_menu[df_menu.physical_description.str.contains(r'\\d', na=False)][['physical_description']]"
   ],
   "id": "c4bea53401a495f1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   physical_description\n",
       "0                       CARD; 4.75X7.5;\n",
       "1            CARD; ILLUS; COL; 7.0X9.0;\n",
       "2             CARD; ILLU; COL; 5.5X8.0;\n",
       "3             CARD; ILLU; COL; 5.5X8.0;\n",
       "4           FOLDER; ILLU; COL; 5.5X7.5;\n",
       "...                                 ...\n",
       "16808  19.5x14cm folded; 19.5x42cm open\n",
       "16809                      19.5x11.5cm \n",
       "16810                        12.5x7.5cm\n",
       "16811  23x16.5cm folded; 23x33cm open  \n",
       "16812  19.5x13cm folded; 19.5x26cm open\n",
       "\n",
       "[14683 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>physical_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARD; 4.75X7.5;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CARD; ILLUS; COL; 7.0X9.0;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CARD; ILLU; COL; 5.5X8.0;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CARD; ILLU; COL; 5.5X8.0;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOLDER; ILLU; COL; 5.5X7.5;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16808</th>\n",
       "      <td>19.5x14cm folded; 19.5x42cm open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16809</th>\n",
       "      <td>19.5x11.5cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16810</th>\n",
       "      <td>12.5x7.5cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16811</th>\n",
       "      <td>23x16.5cm folded; 23x33cm open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16812</th>\n",
       "      <td>19.5x13cm folded; 19.5x26cm open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14683 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:27:24.206500Z",
     "start_time": "2025-02-05T04:27:23.899151Z"
    }
   },
   "cell_type": "code",
   "source": "df_dish = pd.read_csv(os.path.join(data_path, 'Dish.csv'))",
   "id": "855925e33e5ee83c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:27:34.440315Z",
     "start_time": "2025-02-05T04:27:34.435363Z"
    }
   },
   "cell_type": "code",
   "source": "df_dish.name",
   "id": "bc9d3953831ec0a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                Consomme printaniere royal\n",
       "1                                             Chicken gumbo\n",
       "2                                       Tomato aux croutons\n",
       "3                                           Onion au gratin\n",
       "4                                               St. Emilion\n",
       "                                ...                        \n",
       "422034    FILET OF BEEF, piquee, a la Bordelaise, Stuffe...\n",
       "422035                                 ROAST SQUAB ON TOAST\n",
       "422036                 BROILED POMPANO, a la Maitre d'Hotel\n",
       "422037                            Potatoes A La Parisienne \n",
       "422038    BEEF TOMATO ORIENTALE: Our version of a very p...\n",
       "Name: name, Length: 422039, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:50:40.430893Z",
     "start_time": "2025-02-05T04:50:40.426392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lingua import Language, LanguageDetectorBuilder\n",
    "\n",
    "# 定义可识别的语言列表\n",
    "languages = [Language.ENGLISH, Language.FRENCH, Language.GERMAN, Language.SPANISH, Language.ITALIAN]\n",
    "\n",
    "# 创建语言检测器\n",
    "detector = LanguageDetectorBuilder.from_languages(*languages)\\\n",
    ".with_minimum_relative_distance(0.7)\\\n",
    ".build()\n",
    "\n",
    "# # 要检测的混合语言文本\n",
    "# sentence = (\n",
    "#     \"Parlez-vous français? \"\n",
    "#     \"Ich spreche Französisch nur ein bisschen. \"\n",
    "#     \"A little bit is better than nothing.\"\n",
    "# )\n",
    "# \n",
    "# # 检测文本中的多种语言\n",
    "# for result in detector.detect_multiple_languages_in_parallel_of(sentence):\n",
    "#     print(f\"{result.language.name}: '{sentence[result.start_index:result.end_index]}'\")"
   ],
   "id": "5ab185b83cb4f208",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T04:53:22.644294Z",
     "start_time": "2025-02-05T04:53:22.630553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提取前50个菜名，检测其语言\n",
    "for name in df_dish.name[:100]:\n",
    "    # print(type(name))\n",
    "    for result in detector.detect_multiple_languages_of(name.lower()):\n",
    "        print(f\"{result.language.name}: '{name.lower()}'\")"
   ],
   "id": "cd5637b02156546",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRENCH: 'consomme printaniere royal'\n",
      "ENGLISH: 'radishes'\n",
      "ENGLISH: 'clam broth (cup)'\n",
      "ENGLISH: 'clear green turtle'\n",
      "ENGLISH: 'fresh lobsters in every style'\n",
      "ITALIAN: 'whitebait, sauce tartare'\n",
      "ENGLISH: 'cerealine with milk'\n",
      "ENGLISH: 'sliced tomatoes'\n",
      "ENGLISH: 'smoked beef in cream'\n",
      "ENGLISH: 'breakfast'\n",
      "ENGLISH: 'strawberries'\n",
      "ENGLISH: 'preserved figs'\n",
      "FRENCH: 'consomme anglaise'\n",
      "ENGLISH: 'cream of cauliflower'\n",
      "ENGLISH: 'broiled shad, a la maitre d'hotel'\n",
      "ENGLISH: 'sliced cucumbers'\n",
      "ENGLISH: 'salted almonds'\n",
      "ENGLISH: 'potatoes, julien'\n",
      "ENGLISH: 'cracked wheat'\n",
      "ENGLISH: 'malt breakfast food'\n",
      "ENGLISH: 'boiled beef tongue, italian sauce'\n",
      "ENGLISH: 'roast sirloin of beef, yorkshire pudding'\n",
      "GERMAN: 'huhnerbruhe'\n",
      "ENGLISH: 'rockaways'\n",
      "GERMAN: 'hafergrutze'\n",
      "ENGLISH: 'browned potatoes'\n",
      "GERMAN: 'pampelmuse'\n",
      "GERMAN: 'apfelsinen'\n",
      "GERMAN: 'milchreis'\n",
      "GERMAN: 'filet v. schildkrote m. truffeln'\n",
      "GERMAN: 'kraftsuppe, konigliche art'\n",
      "FRENCH: 'consomme in cup'\n",
      "ENGLISH: 'broiled shad, maitre d'hotel'\n",
      "ENGLISH: 'mashed potatoes'\n",
      "ENGLISH: 'breaded veal cutlet with peas'\n",
      "ENGLISH: 'hind-quarter of spring lamb with stuffed tomatoes'\n",
      "FRENCH: 'doucette salad'\n",
      "ENGLISH: 'salisbury steak au cresson'\n",
      "ENGLISH: 'boiled rice'\n",
      "ENGLISH: 'stewed oyster plant'\n",
      "ENGLISH: 'boiled onions, cream sauce'\n",
      "ENGLISH: 'old fashioned rice pudding'\n",
      "ENGLISH: 'coffee'\n",
      "ENGLISH: 'rolled oats'\n",
      "ENGLISH: 'broiled mackerel'\n",
      "ENGLISH: 'kippered herring'\n",
      "ENGLISH: 'strawberries with cream'\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T05:02:40.762499Z",
     "start_time": "2025-02-05T05:02:35.187157Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')  # Download tokenizer data (if you haven't already)\n",
    "nltk.download('averaged_perceptron_tagger') # Download POS tagger data\n",
    "\n",
    "# text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "# tokens = word_tokenize(text)\n",
    "# tagged_words = nltk.pos_tag(tokens)\n",
    "# \n",
    "# adjectives = []\n",
    "# for word, tag in tagged_words:\n",
    "#     if tag.startswith('JJ'):  # NLTK tags for adjectives start with 'JJ' (JJ, JJR, JJS)\n",
    "#         adjectives.append(word)\n",
    "# \n",
    "# print(\"Adjectives:\", adjectives)  # Output: Adjectives: ['quick', 'brown', 'lazy']"
   ],
   "id": "dde6d6f957052a36",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\qingx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\qingx\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001B[93mpunkt_tab\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt_tab/english/\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\qingx/nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\share\\\\nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\qingx\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mLookupError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maveraged_perceptron_tagger\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;66;03m# Download POS tagger data\u001B[39;00m\n\u001B[0;32m      7\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe quick brown fox jumps over the lazy dog.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 8\u001B[0m tokens \u001B[38;5;241m=\u001B[39m word_tokenize(text)\n\u001B[0;32m      9\u001B[0m tagged_words \u001B[38;5;241m=\u001B[39m nltk\u001B[38;5;241m.\u001B[39mpos_tag(tokens)\n\u001B[0;32m     11\u001B[0m adjectives \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:142\u001B[0m, in \u001B[0;36mword_tokenize\u001B[1;34m(text, language, preserve_line)\u001B[0m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mword_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m, preserve_line\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    128\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03m    Return a tokenized copy of *text*,\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended word tokenizer\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;124;03m    :type preserve_line: bool\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 142\u001B[0m     sentences \u001B[38;5;241m=\u001B[39m [text] \u001B[38;5;28;01mif\u001B[39;00m preserve_line \u001B[38;5;28;01melse\u001B[39;00m sent_tokenize(text, language)\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    144\u001B[0m         token \u001B[38;5;28;01mfor\u001B[39;00m sent \u001B[38;5;129;01min\u001B[39;00m sentences \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m _treebank_word_tokenizer\u001B[38;5;241m.\u001B[39mtokenize(sent)\n\u001B[0;32m    145\u001B[0m     ]\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001B[0m, in \u001B[0;36msent_tokenize\u001B[1;34m(text, language)\u001B[0m\n\u001B[0;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msent_tokenize\u001B[39m(text, language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m    110\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001B[39;00m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;124;03m    :param language: the model name in the Punkt corpus\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 119\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m _get_punkt_tokenizer(language)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer\u001B[38;5;241m.\u001B[39mtokenize(text)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001B[0m, in \u001B[0;36m_get_punkt_tokenizer\u001B[1;34m(language)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mlru_cache\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_punkt_tokenizer\u001B[39m(language\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     98\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001B[39;00m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;124;03m    a lru cache for performance.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;124;03m    :type language: str\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m PunktTokenizer(language)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001B[0m, in \u001B[0;36mPunktTokenizer.__init__\u001B[1;34m(self, lang)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1743\u001B[0m     PunktSentenceTokenizer\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m-> 1744\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mload_lang(lang)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001B[0m, in \u001B[0;36mPunktTokenizer.load_lang\u001B[1;34m(self, lang)\u001B[0m\n\u001B[0;32m   1746\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_lang\u001B[39m(\u001B[38;5;28mself\u001B[39m, lang\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m   1747\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m find\n\u001B[1;32m-> 1749\u001B[0m     lang_dir \u001B[38;5;241m=\u001B[39m find(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokenizers/punkt_tab/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlang\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1750\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_params \u001B[38;5;241m=\u001B[39m load_punkt_params(lang_dir)\n\u001B[0;32m   1751\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lang \u001B[38;5;241m=\u001B[39m lang\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\story\\Lib\\site-packages\\nltk\\data.py:579\u001B[0m, in \u001B[0;36mfind\u001B[1;34m(resource_name, paths)\u001B[0m\n\u001B[0;32m    577\u001B[0m sep \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m70\u001B[39m\n\u001B[0;32m    578\u001B[0m resource_not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mmsg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00msep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 579\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mLookupError\u001B[39;00m(resource_not_found)\n",
      "\u001B[1;31mLookupError\u001B[0m: \n**********************************************************************\n  Resource \u001B[93mpunkt_tab\u001B[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001B[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001B[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001B[93mtokenizers/punkt_tab/english/\u001B[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\qingx/nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\share\\\\nltk_data'\n    - 'D:\\\\Anaconda3\\\\envs\\\\story\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\qingx\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
